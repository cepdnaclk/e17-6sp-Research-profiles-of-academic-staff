[
  {
    "type": "inproceedings",
    "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
    "book title": "2017 {IEEE} International Conference on Industrial and Information Systems, {ICIIS} 2017, Peradeniya, Sri Lanka, December 15-16, 2017",
    "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
    "year": "2017",
    "Authors": [
      "Wijethunge, A. H.",
      "Wijekulasooriya, J. V.",
      "Ekanayake, Janaka B.",
      "Samarakoon, Kamalanath",
      "Polpitiya, A."
    ],
    "DOI": "10.1109/ICIINFS.2017.8300374",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ICIINFS.2017.8300374",
    "presentation": "",
    "code": "",
    "tags": [
      "Schedules",
      "Genetic algorithms",
      "Optimization",
      "Wind power generation",
      "Power demand",
      "Wind turbines",
      "Mathematical model",
      "costing",
      "demand side management",
      "domestic appliances",
      "genetic algorithms",
      "scheduling",
      "wind power plants"
    ]
  },
  {
    "type": "article",
    "title": "Support of Mobile Phones in a Private Network for Science Teaching",
    "abstract": "The potential of mobile phones to facilitate students\u2019 science learning, when they are engaging in group activities, was investigated. To minimize the disciplinary issues emerged from the previous research on mobile devices and to enhance the quality of learning, a set of mobile phones that are connected to a private network was used. The lesson planning and implementation through these mobile phones were facilitated by a web based Application. A purposively selected group of teachers developed three lessons while integrating mobile phones in a private network into learning activities. Then the lessons were implemented in real classroom settings. This paper is based on one of the lessons \u2018Waves and their Characteristics\u2019 that was implemented for Grade 11 students. The data were collected through observations using audio, video and field notes and were analyzed using thematic analysis technique with the help of NVivo10 qualitative data analysis software. Based on the thematic analysis, two assertions were derived. Notably teachers appreciated the support of the private network in enhancing the quality of group learning activity while minimizing the students\u2019 misuse of mobile phones.",
    "year": "2016",
    "Authors": [
      "Ekanayake, Sakunthala",
      "Samarakoon, Kamalanath"
    ],
    "venue": {
      "journal": "Int. J. Interact. Mob. Technol.",
      "volume": "10"
    },
    "DOI": "10.3991/ijim.v10i2.4817",
    "pdf": "https://online-journals.org/index.php/i-jim/article/view/4817/3893",
    "publication url": "https://www.online-journals.org/index.php/i-jim/article/view/4817",
    "presentation": "",
    "code": "",
    "tags": [
      "Mobile learning",
      "Science education"
    ]
  },
  {
    "type": "inproceedings",
    "title": "miRNAFinder: {A} pre-microRNA classifier for plants and analysis of feature impact",
    "book title": "{IEEE} Conference on Computational Intelligence in Bioinformatics and Computational Biology, {CIBCB} 2020, Vi{\\~{n}}a del Mar, Chile, October 27-29, 2020",
    "abstract": "MicroRNAs (miRNAs) are endogenous small noncoding RNAs that play an important role in post-transcriptional gene regulation. Several machine learning-based studies have been conducted for miRNA identification with the use of miRNA features. It is difficult to classify real and pseudo-pre-miRNAs in plant species than that in animals since plant pre-miRNAs are more diverse than the animal pre-miRNAs. Therefore, this study is focused on classifying real and pseudo precursor miRNAs (pre-miRNAs) in plants. We have introduced a machine learning model based on a 280 feature set including compositional, sequence-based, and thermodynamic features. Classification performance is tested and compared, considering different feature sets and four different classifiers. Random forest classifier results in the best classification performance with all 280 features with a 97% accuracy for the testing dataset.",
    "year": "2020",
    "Authors": [
      "Ihalagedara, Puwasuru",
      "Lokuge, Sandali",
      "Jayasundara, Shyaman",
      "Herath, Damayanthi",
      "Kahanda, Indika"
    ],
    "DOI": "10.1109/CIBCB48159.2020.9277723",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/CIBCB48159.2020.9277723",
    "presentation": "",
    "code": "",
    "tags": [
      "Feature extraction",
      "RNA",
      "Support vector machines",
      "Testing",
      "Animals",
      "Vegetation",
      "Random forests",
      "bioinformatics",
      "genetics",
      "genomics",
      "macromolecules",
      "molecular biophysics",
      "pattern classification",
      "random forests",
      "RNA"
    ]
  },
  {
    "type": "article",
    "title": "ENVirT: inference of ecological characteristics of viruses from metagenomic data",
    "abstract": "In this paper, we present ENVirT, a method for estimating the richness of novel viral mixtures, and for the first time we also show that it is possible to simultaneously estimate the average genome length without a priori information. This is shown to be a significant improvement over database-dependent methods, since we can now robustly analyze samples that may include novel viral types under-represented in current databases. We demonstrate that the viral richness estimates produced by ENVirT are several orders of magnitude higher in accuracy than the estimates produced by existing methods named PHACCS and CatchAll when benchmarked against simulated data. We repeated the analysis of 20 metavirome samples using ENVirT, which produced results in close agreement with complementary in virto analyses.",
    "year": "2019",
    "Authors": [
      "Jayasundara, Duleepa",
      "Herath, Damayanthi",
      "Senanayake, Damith A.",
      "Saeed, Isaam",
      "Yang, Cheng{-}Yu",
      "Sun, Yuan",
      "Chang, Bill C.",
      "Tang, Sen{-}Lin",
      "Halgamuge, Saman K."
    ],
    "venue": {
      "journal": "{BMC} Bioinform.",
      "volume": "19-S"
    },
    "DOI": "10.1186/s12859-018-2398-5",
    "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-018-2398-5.pdf",
    "publication url": "https://doi.org/10.1186/s12859-018-2398-5",
    "presentation": "",
    "code": "",
    "tags": [
      "Richness estimation",
      "Viral metagenomics",
      "Average genome length"
    ]
  },
  {
    "type": "article",
    "title": "CoMet: a workflow using contig coverage and composition for binning a metagenomic sample with high precision",
    "abstract": "Binning methods based on both compositional features and coverages of contigs had higher performances than the method which is based only on compositional features of contigs. CoMet yielded higher or comparable precision in comparison to the existing binning methods on benchmark datasets of varying complexities. MyCC (coverage) had the highest ranking score in F1-score. However, the performances of CoMet were higher than MyCC (coverage) on the dataset containing multiple strains. Furthermore, CoMet recovered contigs of more species and was 18 - 39% higher in precision than the compared existing methods in discriminating species from the sample of multiple strains. CoMet resulted in higher precision than MyCC (default) and MyCC (coverage) on a real metagenome.",
    "year": "2017",
    "Authors": [
      "Herath, Damayanthi",
      "Tang, Sen{-}Lin",
      "Tandon, Kshitij",
      "Ackland, David C.",
      "Halgamuge, Saman Kumara"
    ],
    "venue": {
      "journal": "{BMC} Bioinform.",
      "volume": "18"
    },
    "DOI": "10.1186/s12859-017-1967-3",
    "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-017-1967-3.pdf",
    "publication url": "https://doi.org/10.1186/s12859-017-1967-3",
    "presentation": "",
    "code": "",
    "tags": [
      "Metagenomics",
      "Binning",
      "Contig coverage",
      "Contig composition",
      "DBSCAN algorithm"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Transfer Learning for Accurate and Efficient Tomato Plant Disease Classification Using Leaf Images",
    "book title": "16th International Conference on Industrial and Information Systems, {ICIIS} 2021, Kandy, Sri Lanka, September 12 - Nov. 12, 2021",
    "abstract": "Plant leaf diseases cause great damage to crops, resulting in significant yield losses. Traditionally, identification of plant leaf diseases depends on human annotation by visual inspection. Transfer learning has enabled use of existing solutions in one domain to problems from another domain, resulting in more robust and efficient solutions. This work presents a method to identify tomato plant diseases based on leaf images using transfer learning. We used a publicly available dataset which contains tomato plant leaf images for 10 different classes. We considered only five classes and data was split in ratio 8:1:1 for train, validation and test sets respectively. In this work, six different pre trained models were used with fine-tuning methods where we introduced some layers and removed some layers in the network architectures while enhancing the accuracy of models. Accuracies of all the models were above 97% except one model which got 95% accuracy on the testing. Precision, Recall, F1 Score, Confusion matrix and Classification reports were used for evaluations and finally a novel convolutional neural network is proposed for plant disease classification focusing on a real environment. The mentioned model achieved an accuracy of 99.98% on training and an accuracy of 99% on testing. In this work, a good generalization performance could be achieved without data augmentation. The experimental results show that the proposed fine-tuned architecture is effective in identifying tomato leaf diseases and it could be generalized to identify leaf diseases in other plants.",
    "year": "2021",
    "Authors": [
      "Deshan, L. A. Chamli",
      "Thisanke, M. K. Hans",
      "Herath, Damayanthi"
    ],
    "DOI": "10.1109/ICIIS53135.2021.9660681",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ICIIS53135.2021.9660681",
    "presentation": "",
    "code": "",
    "tags": [
      "Training",
      "Visualization",
      "Annotations",
      "Transfer learning",
      "Neural networks",
      "Optimization methods",
      "Inspection",
      "agriculture",
      "crops",
      "diseases",
      "feature extraction",
      "image classification",
      "image recognition",
      "image segmentation",
      "learning (artificial intelligence)",
      "neural nets",
      "pattern classification",
      "plant diseases"
    ]
  },
  {
    "type": "article",
    "title": "Machine learning for plant microRNA prediction: {A} systematic review",
    "abstract": "MicroRNAs (miRNAs) are endogenous small non-coding RNAs that play an important role in posttranscriptional gene regulation. However, the experimental determination of miRNA sequence and structure is both expensive and time-consuming. Therefore, computational and machine learning-based approaches have been adopted to predict novel microRNAs. With the involvement of data science and machine learning in biology, multiple research studies have been conducted to find microRNAs with different computational methods and different miRNA features. Multiple approaches are discussed in detail considering the learning algorithm/s used, features considered, dataset/s used and the criteria used in evaluations. This systematic review focuses on the machine learning methods developed for miRNA identification in plants. This will help researchers to gain a detailed idea about past studies and identify novel paths that solve drawbacks occurred in past studies. Our findings highlight the need for plant-specific computational methods for miRNA identification.",
    "year": "2021",
    "Authors": [
      "Jayasundara, Shyaman",
      "Lokuge, Sandali",
      "Ihalagedara, Puwasuru",
      "Herath, Damayanthi"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/2106.15159"
    },
    "DOI": "10.48550/arXiv.2106.15159",
    "pdf": "https://arxiv.org/pdf/2106.15159",
    "publication url": "https://arxiv.org/abs/2106.15159",
    "presentation": "",
    "code": "",
    "tags": [
      "bioinformatics",
      "novel miRNA",
      "machine learning",
      "microRNA",
      "plant",
      "systematic review",
      "prediction"
    ]
  },
  {
    "type": "inproceedings",
    "title": "A computational model to evaluate honesty in social internet of things",
    "book title": "Proceedings of the Symposium on Applied Computing - {SAC} {\\textquotesingle}17",
    "abstract": "Trust in Social Internet of Things has allowed to open new horizons in collaborative networking, particularly by allowing objects to communicate with their service providers, based on their relationships analogy to human world. However, strengthening trust is a challenging task as it involves identifying several influential factors in each domain of social-cyber-physical systems in order to build a reliable system. In this paper, we address the issue of understanding and evaluating honesty that is an important trust metric in trustworthiness evaluation process in social networks. First, we identify and define several trust attributes, which affect directly to the honesty. Then, a subjective computational model is derived based on experiences of objects and opinions from friendly objects with respect to identified attributes. Based on the outputs of this model a final honest level is predicted using regression analysis. Finally, the effectiveness of our model is tested using simulations.",
    "year": "2017",
    "Authors": [
      "Jayasinghe, Upul",
      "Lee, Hyun-Woo",
      "Lee, Gyu Myoung"
    ],
    "DOI": "10.1145/3019612.3019840",
    "pdf": "",
    "publication url": "https://doi.org/10.1145%2F3019612.3019840",
    "presentation": "",
    "code": "",
    "tags": "SIoT"
  },
  {
    "type": "article",
    "title": "Genopo: a nanopore sequencing analysis toolkit for portable Android devices",
    "abstract": "The advent of portable nanopore sequencing devices has enabled DNA and RNA sequencing to be performed in the field or the clinic. However, advances in in situ genomics require parallel development of portable, offline solutions for the computational analysis of sequencing data. Here we introduce Genopo, a mobile toolkit for nanopore sequencing analysis. Genopo compacts popular bioinformatics tools to an Android application, enabling fully portable computation. To demonstrate its utility for in situ genome analysis, we use Genopo to determine the complete genome sequence of the human coronavirus SARS-CoV-2 in nine patient isolates sequenced on a nanopore device, with Genopo executing this workflow in less than 30\u2009min per sample on a range of popular smartphones. We further show how Genopo can be used to profile DNA methylation in a human genome sample, illustrating a flexible, efficient architecture that is suitable to run many popular bioinformatics tools and accommodate small or large genomes. As the first ever smartphone application for nanopore sequencing analysis, Genopo enables the genomics community to harness this cheap, ubiquitous computational resource.",
    "year": "2020",
    "Authors": [
      "Samarakoon, Hiruna",
      "Punchihewa, Sanoj",
      "Senanayake, Anjana",
      "Hammond, Jillian M.",
      "Stevanovski, Igor",
      "Ferguson, James M.",
      "Ragel, Roshan",
      "Gamaarachchi, Hasindu",
      "Deveson, Ira W."
    ],
    "venue": {
      "journal": "Communications Biology",
      "volume": "3"
    },
    "DOI": "10.1038/s42003-020-01270-z",
    "pdf": "https://www.nature.com/articles/s42003-020-01270-z.pdf",
    "publication url": "https://doi.org/10.1038%2Fs42003-020-01270-z",
    "presentation": "",
    "code": "",
    "tags": [
      "Computational platforms and environments",
      "DNA sequencing"
    ]
  },
  {
    "type": "inproceedings",
    "title": "{RpR}: A Trust Computation Model for Social Internet of Things",
    "book title": "2016 Intl {IEEE} Conferences on Ubiquitous Intelligence {\\&} Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress ({UIC}/{ATC}/{ScalCom}/{CBDCom}/{IoP}/{SmartWorld})",
    "abstract": "Social Internet of Things (SIoT) is an evolutionary idea which combines traditional IoT models with social network paradigms. Objects in SIoT formulate social relationships with other trusted objects according to the relationships of their owners which deliver trustworthy services on request. From our trust platform concept to identify vital trust metrics, attributes, we propose a Recommendations plus Reputations based Trust Computational Model (RpR) that enables objects in SIoT to build associations in a trustworthy manner. A numerical model is developed to estimate trust of each object based on Recommendation, Reputation parameters. Next, both estimates are merged together, a robust algorithm is proposed. Finally, we demonstrate, validate the usefulness of RpR over prior approaches through simulations, analysis. The aim of our approach is to facilitate accurate modeling of trustworthiness in distributed SIoT environments.",
    "year": "2016",
    "Authors": [
      "Jayasinghe, Upul",
      "Truong, Nguyen B.",
      "Lee, Gyu Myoung",
      "Um, Tai-Won"
    ],
    "DOI": "10.1109/uic-atc-scalcom-cbdcom-iop-smartworld.2016.0146",
    "pdf": "",
    "publication url": "https://doi.org/10.1109%2Fuic-atc-scalcom-cbdcom-iop-smartworld.2016.0146",
    "presentation": "",
    "code": "",
    "tags": [
      "Social Networks",
      "SIoT",
      "Trust Computation",
      "Trust Model",
      "Knowledge",
      "Reputation",
      "Recommendation"
    ]
  },
  {
    "type": "article",
    "title": "CoMet: A workflow using contig coverage and composition for binning a metagenomic sample with high precision",
    "abstract": "Background: In metagenomics, the separation of nucleotide sequences belonging to an individual or closely matched populations is termed binning. Binning helps the evaluation of underlying microbial population structure as well as the recovery of individual genomes from a sample of uncultivable microbial organisms. Both supervised and unsupervised learning methods have been employed in binning; however, characterizing a metagenomic sample containing multiple strains remains a significant challenge. In this study, we designed and implemented a new workflow, Coverage and composition based binning of Metagenomes (CoMet), for binning contigs in a single metagenomic sample. CoMet utilizes coverage values and the compositional features of metagenomic contigs. The binning strategy in CoMet includes the initial grouping of contigs in guanine-cytosine (GC) content-coverage space and refinement of bins in tetranucleotide frequencies space in a purely unsupervised manner. With CoMet, the clustering algorithm DBSCAN is employed for binning contigs. The performances of CoMet were compared against four existing approaches for binning a single metagenomic sample, including MaxBin, Metawatt, MyCC (default) and MyCC (coverage) using multiple datasets including a sample comprised of multiple strains. Results: Binning methods based on both compositional features and coverages of contigs had higher performances than the method which is based only on compositional features of contigs. CoMet yielded higher or comparable precision in comparison to the existing binning methods on benchmark datasets of varying complexities. MyCC (coverage) had the highest ranking score in F1-score. However, the performances of CoMet were higher than MyCC (coverage) on the dataset containing multiple strains. Furthermore, CoMet recovered contigs of more species and was 18 - 39% higher in precision than the compared existing methods in discriminating species from the sample of multiple strains. CoMet resulted in higher precision than MyCC (default) and MyCC (coverage) on a real metagenome. Conclusions: The approach proposed with CoMet for binning contigs, improves the precision of binning while characterizing more species in a single metagenomic sample and in a sample containing multiple strains. The F1-scores obtained from different binning strategies vary with different datasets; however, CoMet yields the highest F1-score with a sample comprised of multiple strains.",
    "year": "2017",
    "Authors": [
      "Herath, D.",
      "Tang, S.-L.",
      "Tandon, K.",
      "Ackland, D.",
      "Halgamuge, S.K."
    ],
    "venue": {
      "journal": "BMC Bioinformatics",
      "volume": "18"
    },
    "DOI": "10.1186/s12859-017-1967-3",
    "pdf": "",
    "publication url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1967-3",
    "presentation": "",
    "code": "",
    "tags": [
      "Metagenomics",
      "Binning",
      "Contig coverage",
      "Contig composition",
      "DBSCAN algorithm"
    ]
  },
  {
    "type": "article",
    "title": "Accelerating string matching for bio-computing applications on multi-core CPUs",
    "abstract": "Huge amount of data in the form of strings are being handled in bio-computing applications and searching algorithms are quite frequently used in them. Many methods utilizing on both software and hardware are being proposed to accelerate processing of such data. The typical hardware-based acceleration techniques either require special hardware such as generalpurpose graphics processing units (GPGPUs) or need building a new hardware such as an FPGA based design. On the other hard, software-based acceleration techniques are easier since they only require some changes in the software code or the software architecture. Typical software-based techniques make use of computers connected over a network, also known as a network grid to accelerate the processing. In this paper, we test the hypothesis that multi-core architectures should provide better performance in this kind of computation, but still it would depend on the algorithm selected as well as the programming model being utilized. We present the acceleration of a string-searching algorithm on a multi-core CPU via a POSIX thread based implementation. Our implementation on an 8-core processor (that supports 16-threads) resulted in 9x throughput improvement compared to a single thread implementation.",
    "year": "2012",
    "Authors": [
      "Herath, D.",
      "Lakmali, C.",
      "Ragel, R."
    ],
    "venue": {
      "journal": "2012 IEEE 7th International Conference on Industrial and Information Systems, ICIIS 2012"
    },
    "DOI": "10.1109/ICIInfS.2012.6304784",
    "pdf": "",
    "publication url": "https://ieeexplore.ieee.org/document/6304784",
    "presentation": "",
    "code": "",
    "tags": [
      "bio-computing algorithms",
      "multi-core processor",
      "POSIX threads",
      "string matching",
      "Multi core",
      "Program processors"
    ]
  },
  {
    "type": "article",
    "title": "Analysis of four historical ciphers against known plaintext frequency statistical attack",
    "abstract": "The need of keeping information securely began thousands of years. The practice to keep the information securely is by scrambling the message into unreadable form namely ciphertext. This process is called encryption. Decryption is the reverse process of encryption. For the past, historical ciphers are used to perform encryption and decryption process. For example, the common historical ciphers are Hill cipher, Playfair cipher, Random Substitution cipher and Vigen\u00e8re cipher. This research is carried out to examine and to analyse the security level of these four historical ciphers by using known plaintext frequency statistical attack. The result had shown that Playfair cipher and Hill cipher have better security compare with Vigen\u00e8re cipher and Random Substitution cipher.",
    "year": "2018",
    "Authors": [
      "Wen, C.C.",
      "Samylingam, V.",
      "Darmawan, I.",
      "Palaniappan, P.S.S.",
      "Foozy, C.F.M.",
      "Ramli, S.N.",
      "Alawatugoda, J."
    ],
    "venue": {
      "journal": "International Journal of Integrated Engineering",
      "volume": "10"
    },
    "DOI": "",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85059297055&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      " Cryptanalysis",
      "Cipher",
      "Encryption",
      "Hill Cipher",
      "Historical Ciphers",
      "Known",
      "Playfair Cipher",
      "Random Substitution Cipher",
      "Vigen\u00e8re Cipher"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Application of a leakage based precoding scheme to mitigate intrinsic interference in {FBMC}",
    "book title": "2013 {IEEE} International Conference on Communications ({ICC})",
    "abstract": "Orthogonal frequency division multiplexing with offset QAM (OFDM/OQAM) modulation scheme, more commonly known as filter bank multicarrier (FBMC), has received greater attention recently, due to its spectral efficiency compared to standard OFDM. However, intrinsic interference in FBMC causes a negative effect on the system performance depending on the channel condition. Hence, in this paper, we analyze the interference in OFDM/OQAM systems and introduce a preceder based on signal-to-leakage-plus-noise ratio (SLNR) to overcome the effect of interference on the system. First we implement the system in a more efficient way using inverse fast Fourier transform (IFFT). Then based on that model, the precoding matrix is generated. Finally through simulation and analysis, reduction of interference and improvement of performance are investigated.",
    "year": "2013",
    "Authors": [
      "Jayasinghe, Upul",
      "Rajatheva, Nandana",
      "Latva-aho, Matti"
    ],
    "DOI": "10.1109/icc.2013.6655423",
    "pdf": "",
    "publication url": "https://doi.org/10.1109%2Ficc.2013.6655423",
    "presentation": "",
    "code": "",
    "tags": [
      "FBMC",
      "OFDM/OQAM",
      "MCM",
      "D7FT",
      "SINK",
      "SLNR",
      "SNR",
      "Equalization",
      "BER"
    ]
  },
  {
    "type": "article",
    "title": "Assessing Species Diversity Using Metavirome Data: Methods and Challenges",
    "abstract": "",
    "year": "2017",
    "Authors": [
      "Herath, D.",
      "Jayasundara, D.",
      "Ackland, D.",
      "Saeed, I.",
      "Tang, S.-L.",
      "Halgamuge, S."
    ],
    "venue": {
      "journal": "Computational and Structural Biotechnology Journal",
      "volume": "15"
    },
    "DOI": "10.1016/j.csbj.2017.09.001",
    "pdf": "https://www.sciencedirect.com/science/article/pii/S2001037017300223/pdfft?isDTMRedir=true&download=true",
    "publication url": "https://www.sciencedirect.com/science/article/pii/S2001037017300223?via%3Dihub",
    "presentation": "",
    "code": "",
    "tags": [
      "Biodiversity",
      "Bioinformatics",
      "Metagenomics",
      "Metavirome data",
      "Phage studies",
      "Species diversity"
    ]
  },
  {
    "type": "article",
    "title": "{BAT}{\\textemdash}Block Analytics Tool Integrated with Blockchain Based {IoT} Platform",
    "abstract": "The Internet of Things (IoT) is the novel paradigm of connectivity and the driving force behind state-of-the-art applications and services. However, the exponential growth of the number of IoT devices and services, their distributed nature, and scarcity of resources has increased the number of security and privacy concerns ranging from the risks of unauthorized data alterations to the potential discrimination enabled by data analytics over sensitive information. Thus, a blockchain based IoT-platform is introduced to address these issues. Built upon the tamper-proof architecture, the proposed access management mechanisms ensure the authenticity and integrity of data. Moreover, a novel approach called Block Analytics Tool (BAT), integrated with the platform is proposed to analyze and make predictions on data stored on the blockchain. BAT enables the data-analysis applications to be developed using the data stored in the platform in an optimized manner acting as an interface to off-chain processing. A pharmaceutical supply chain is used as the use case scenario to show the functionality of the proposed platform. Furthermore, a model to forecast the demand of the pharmaceutical drugs is investigated using a real-world data set to demonstrate the functionality of BAT. Finally, the performance of BAT integrated with the platform is evaluated.",
    "year": "2020",
    "Authors": [
      "Edussuriya, Chathurangi",
      "Vithanage, Kasun",
      "Bandara, Namila",
      "Alawatugoda, Janaka",
      "Sandirigama, Manjula",
      "Jayasinghe, Upul",
      "Shone, Nathan",
      "Lee, Gyu Myoung"
    ],
    "venue": {
      "journal": "Electronics",
      "volume": "9"
    },
    "DOI": "10.3390/electronics9091525",
    "pdf": "",
    "publication url": "https://www.mdpi.com/2079-9292/9/9/1525",
    "presentation": "",
    "code": "",
    "tags": [
      "IoT",
      "blockchain",
      "data analytics",
      "smart contracts",
      "access management"
    ]
  },
  {
    "type": "article",
    "title": "Continuous after-the-fact leakage-resilient eCK-secure key exchange",
    "abstract": "Security models for two-party authenticated key exchange (AKE) protocols have developed over time to capture the security of AKE protocols even when the adversary learns certain secret values. Increased granularity of security can be modelled by considering partial leakage of secrets in the manner of models for leakage-resilient cryptography, designed to capture side-channel attacks. In this work, we use the strongest known partial-leakage-based security model for key exchange protocols, namely continuous after-the-fact leakage eCK (CAFL-eCK) model. We resolve an open problem by constructing the first concrete two-pass leakage-resilient key exchange protocol that is secure in the CAFL-eCK model. ",
    "year": "2015",
    "Authors": [
      "Alawatugoda, J.",
      "Stebila, D.",
      "Boyd, C."
    ],
    "venue": {
      "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "volume": "9496"
    },
    "DOI": "10.1007/978-3-319-27239-9_17",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84951873341&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "After-the-fact leakage",
      "Key exchange protocols",
      "Leakage-resilience",
      "Security models",
      "Side-channel attacks",
      "Public Key Encryption",
      "Related-Key Attack",
      "Leakage",
      "Cryptography"
    ]
  },
  {
    "type": "article",
    "title": "Continuous after-the-fact leakage-resilient key exchange",
    "abstract": "Security models for two-party authenticated key exchange (AKE) protocols have developed over time to provide security even when the adversary learns certain secret keys. In this work, we advance the modelling of AKE protocols by considering more granular, continuous leakage of long-term secrets of protocol participants: the adversary can adaptively request arbitrary leakage of long-term secrets even after the test session is activated, with limits on the amount of leakage per query but no bounds on the total leakage. We present a security model supporting continuous leakage even when the adversary learns certain ephemeral secrets or session keys, and give a generic construction of a two-pass leakage-resilient key exchange protocol that is secure in the model; our protocol achieves continuous, after-the-fact leakage resilience with not much more cost than a previous protocol with only bounded, non-after-the-fact leakage.",
    "year": "2014",
    "Authors": [
      "Alawatugoda, J.",
      "Boyd, C.",
      "Stebila, D."
    ],
    "venue": {
      "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "volume": "8544 LNCS"
    },
    "DOI": " 10.1007/978-3-319-08344-5_17",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84904176606&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "after-the-fact leakage",
      "continuous leakage",
      "key exchange",
      "leakage resilience",
      "security models",
      "Public Key Encryption",
      "Related-Key Attack"
    ]
  },
  {
    "type": "article",
    "title": "Countermeasures against Bernstein{'}s remote cache timing attack",
    "abstract": "Cache timing attack is a type of side channel attack where the leaking timing information due to the cache behaviour of a crypto system is used by an attacker to break the system. Advanced Encryption Standard (AES) was considered a secure encryption standard until 2005 when Daniel Bernstein claimed that the software implementation of AES is vulnerable to cache timing attack. Bernstein demonstrated a remote cache timing attack on a software implementation of AES. The original AES implementation can methodically be altered to prevent the cache timing attack by hiding the natural cache-timing pattern during the encryption while preserving its semantics. The alternations while preventing the attack should not make the implementation very slow. In this paper, we report outcomes of our experiments on designing and implementing a number of possible countermeasures.",
    "year": "2011",
    "Authors": [
      "Alawatugoda, J.",
      "Jayasinghe, D.",
      "Ragel, R."
    ],
    "venue": {
      "journal": "2011 6th International Conference on Industrial and Information Systems, ICIIS 2011 - Conference Proceedings"
    },
    "DOI": " 10.1109/ICIINFS.2011.6038038",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-80054889643&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Advanced Encryption Standard",
      "Cache Timing Attack",
      "Preventing Remote Attacks",
      "Side Channel Attack"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Data centric trust evaluation and prediction framework for {IOT}",
    "book title": "2017 {ITU} Kaleidoscope: Challenges for a Data-Driven Society ({ITU} K)",
    "abstract": "Application of trust principals in internet of things (IoT) has allowed to provide more trustworthy services among the corresponding stakeholders. The most common method of assessing trust in IoT applications is to estimate trust level of the end entities (entity-centric) relative to the trustor. In these systems, trust level of the data is assumed to be the same as the trust level of the data source. However, most of the IoT based systems are data centric and operate in dynamic environments, which need immediate actions without waiting for a trust report from end entities. We address this challenge by extending our previous proposals on trust establishment for entities based on their reputation, experience and knowledge, to trust estimation of data items [1-3]. First, we present a hybrid trust framework for evaluating both data trust and entity trust, which will be enhanced as a standardization for future data driven society. The modules including data trust metric extraction, data trust aggregation, evaluation and prediction are elaborated inside the proposed framework. Finally, a possible design model is described to implement the proposed ideas.",
    "year": "2017",
    "Authors": [
      "Jayasinghe, Upul",
      "Otebolaku, Abayomi",
      "Um, Tai-Won",
      "Lee, Gyu Myoung"
    ],
    "DOI": "10.23919/itu-wt.2017.8246999",
    "pdf": "",
    "publication url": "https://doi.org/10.23919%2Fitu-wt.2017.8246999",
    "presentation": "",
    "code": "",
    "tags": [
      "'Data Trust",
      "Collaborative Filtering",
      "Ensemble Learning"
    ]
  },
  {
    "type": "article",
    "title": "Generic construction of an eCK -secure key exchange protocol in the standard model",
    "abstract": "LaMacchia, Lauter and Mityagin presented a strong security model for authenticated key agreement, namely the eCK model. They also constructed a protocol, namely the NAXOS protocol, that enjoys a simple security proof in the eCK model. However, the NAXOS protocol uses a random oracle-based technique to combine the long-term secret key and the per session randomness, so-called NAXOS trick, in order to achieve the eCK security definition. For NAXOS trick-based protocols, the leakage of per session randomness modeled in the eCK model is somewhat unnatural, because the eCK model leaks per session randomness, while the output of the NAXOS trick computation remains safe. In this work, we present a standard model eCK -secure protocol construction, eliminating the NAXOS trick. Moreover, our protocol is a generic construction, which can be instantiated with arbitrary suitable cryptographic primitives. Thus, we present a generic eCK -secure, NAXOS-free, standard model key exchange protocol. To the best of our knowledge this is the first paper on generic transformation of a CCA 2 -secure public-key encryption scheme to an eCK -secure key exchange protocol in the standard model",
    "year": "2017",
    "Authors": [
      "Alawatugoda, J."
    ],
    "venue": {
      "journal": "International Journal of Information Security",
      "volume": "16"
    },
    "DOI": " 10.1007/s10207-016-0346-9",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84982957794&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "eCK modelKey exchange protocols",
      "Public-key cryptography",
      "Standard model",
      "Public Key Encryption",
      "Related-Key Attack",
      "Leakage"
    ]
  },
  {
    "type": "article",
    "title": "Impact of antenna correlation on the performance of partial relay selection",
    "abstract": "Antenna correlation is generally viewed as an obstacle to realize the desired performance of a wireless system. In this article, we investigate the performance of partial relay selection in the presence of antenna correlation. We consider both channel state information (csi)-assisted and fixed gain amplify-and-forward (AF) relay schemes. The source and the destination are equipped with multiple antennas communicating via the best first hop signal-to-noise ratio (SNR) relay. We derived the closed form expression for outage probability, average symbol error rate (SER) for both schemes. Further, an exact expression is derived for the ergodic capacity in the csi-assisted relay case and an approximated expression is considered for the fixed gain case. Moreover, we provide simple asymptotic results and show that the diversity order of the system remains unchanged with the effect of antenna correlation for both types of relay schemes.",
    "year": "2012",
    "Authors": [
      "Ferdinand, Nuwan S",
      "Jayasinghe, Upul",
      "Rajatheva, Nandana",
      "Latva-aho, Matti"
    ],
    "venue": {
      "journal": "{EURASIP} Journal on Wireless Communications and Networking",
      "volume": "2012"
    },
    "DOI": " 10.1186/1687-1499-2012-261",
    "pdf": "",
    "publication url": "https://doi.org/10.1186%2F1687-1499-2012-261",
    "presentation": "",
    "code": "",
    "tags": [
      "Antenna Correlation",
      "Partial Relay Selection",
      "Ergodic Capacity",
      "Outage Probability",
      "Relay Scheme"
    ]
  },
  {
    "type": "article",
    "title": "Implementing a secure key exchange protocol for OpenSSL",
    "abstract": "Security models have been developed over time to examine the security of two-party authenticated key exchange protocols. In 2007, a reasonably strong security model for key exchange protocols has been proposed, namely extended Canetti-Krawczyk model (eCK model), addressing wide range of real-world attack scenarios. They constructed a protocol called NAXOS, that is proven secure in the eCK model. In order to satisfy the eCK security, NAXOS protocol uses a hash function to combine the ephemeral key with the long-term secret key, which is often called as NAXOS trick. However, for the NAXOS trick based protocols, the way of leakage modelled in the eCK model leads to an unnatural assumption of leak-free computation of the hash function. In 2015, Alawatugoda, Stebila and Boyd presented a secure and NAXOS trick key exchange protocol, namely protocol P1. In this work, we implement the protocol P1 to be used with the widely-used OpenSSL cryptographic library. OpenSSL implementations are widely used with the real-world security protocol suites, particularly Security Socket Layer and Transport Layer Security. According to our knowledge, this is the first implementation of an eCK-secure protocol for the OpenSSL library. Thus, we open up the direction to use the recent advancements of cryptography for real-world Internet communication.",
    "year": "2018",
    "Authors": [
      "Alawatugoda, J.",
      "Vivekaanathan, S.",
      "Peiris, N.",
      "Wickramasinghe, C.",
      "Wen, C.C."
    ],
    "venue": {
      "journal": "International Journal on Advanced Science, Engineering and Information Technology",
      "volume": "8"
    },
    "DOI": " 10.18517/ijaseit.8.5.5046",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85056284097&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Authenticated key exchange",
      "ECK mode",
      "OpenSSL",
      "Secure key",
      "Security models",
      "Authentication",
      "Password"
    ]
  },
  {
    "type": "article",
    "title": "ENVirT: Inference of ecological characteristics of viruses from metagenomic data",
    "abstract": "Assessing biodiversity is an important step in the study of microbial ecology associated with a given environment. Multiple indices have been used to quantify species diversity, which is a key biodiversity measure. Measuring species diversity of viruses in different environments remains a challenge relative to measuring the diversity of other microbial communities. Metagenomics has played an important role in elucidating viral diversity by conducting metavirome studies; however, metavirome data are of high complexity requiring robust data preprocessing and analysis methods. In this review, existing bioinformatics methods for measuring species diversity using metavirome data are categorised broadly as either sequence similarity-dependent methods or sequence similarity-independent methods. The former includes a comparison of DNA fragments or assemblies generated in the experiment against reference databases for quantifying species diversity, whereas estimates from the latter are independent of the knowledge of existing sequence data. Current methods and tools are discussed in detail, including their applications and limitations. Drawbacks of the state-of-the-art method are demonstrated through results from a simulation. In addition, alternative approaches are proposed to overcome the challenges in estimating species diversity measures using metavirome data.",
    "year": "2019",
    "Authors": [
      "Jayasundara, D.",
      "Herath, D.",
      "Senanayake, D.",
      "Saeed, I.",
      "Yang, C.-Y.",
      "Sun, Y.",
      "Chang, B.C.",
      "Tang, S.-L.",
      "Halgamuge, S.K."
    ],
    "venue": {
      "journal": "BMC Bioinformatics",
      "volume": "19"
    },
    "DOI": "10.1186/s12859-018-2398-5",
    "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-018-2398-5.pdf",
    "publication url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2398-5",
    "presentation": "",
    "code": "",
    "tags": [
      "Biodiversity",
      "Bioinformatics",
      "Metagenomics",
      "Metavirome data",
      "Phage studies",
      "Species diversity"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Leakage Based Multi User Beamforming Scheme to Mitigate Interference in MIMO-FBMC",
    "book title": "WSA 2013; 17th International ITG Workshop on Smart Antennas",
    "abstract": "Filter Bank Multicarrier (FBMC) transmission system received much attention recently as an alternative multicarrier modulation (MCM) technique compared to OFDM due to its higher spectral efficiency and less susceptibility to synchronization errors. However, the degradation of performance in multi stream FBMC is comparatively high even with perfect channel state information (CSI) because of interference between users. Hence, in this paper we analyze the inter-user interference in multi user MIMO-FBMC systems and introduce a novel beamforming/precoding technique based on signal-to-leakageplus- noise ratio (SLNR) to overcome the effect of interference among users in the system. The implementation is considered using inverse fast Fourier transform (IFFT). With the use of that the beamforming/precoding matrix is generated. Analysis and simulation results are provided to observe the performance of the system.",
    "year": "2013",
    "Authors": [
      "Jayasinghe, U.",
      "Rajatheva, N.",
      "Latva-aho, M."
    ],
    "DOI": "",
    "publication url": "https://ieeexplore.ieee.org/document/6780676/",
    "pdf": "",
    "presentation": "",
    "code": "",
    "tags": ""
  },
  {
    "type": "article",
    "title": "Leakage-resilient non-interactive key exchange in the continuous-memory leakage setting",
    "abstract": "Recently, Chakraborty et al. (Cryptoeprint:2017:441) showed a novel approach of constructing several leakage-resilient cryptographic primitives by introducing a new primitive called leakage-resilient non-interactive key exchange (LR-NIKE). Their construction of LR-NIKE was only in the bounded-memory leakage model, and they left open the construction of LR-NIKE in continuous-memory leakage model. In this paper we address that open problem. Moreover, we extend the continuous-memory leakage model by addressing more realistic after-the-fact leakage. The main ingredients of our construction are a leakage-resilient storage scheme and a refreshing protocol (Dziembowski and Faust, Asiacrypt 2011) and a (standard) chameleon hash function (CHF), equipped with an additional property of oblivious sampling, which we introduce. We observe that the present constructions of CHF already satisfies our new notion. Further, our protocol can be used as a building block to construct leakage-resilient public-key encryption schemes, interactive key exchange and low-latency key exchange protocols in the continuous-memory leakage model, following the approach of Chakraborty et al. (Cryptoeprint:2017:441).",
    "year": "2017",
    "Authors": [
      "Chakraborty, S.",
      "Alawatugoda, J.",
      "Pandu Rangan, C."
    ],
    "venue": {
      "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "volume": "10592 LNCS"
    },
    "DOI": "10.1007/978-3-319-68637-0_10",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85032704882&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "After-the-fact leakage",
      "Continuous-memory leakage",
      "Key exchange protocols",
      "Leakage-resilient"
    ]
  },
  {
    "type": "article",
    "title": "Leakage-resilient storage scheme for cryptographic applications",
    "abstract": "Since the side-channel attacks arise as a huge threat for cryptographic schemes than previously realized, it is necessary to implement proven-secure leakage-resilient cryptographic schemes and use them for real-world purposes. In this work our effort is to implement two leakage-resilient cryptographic schemes, a leakage-resilient storage scheme and a refreshing protocol, which have been proven-secure and accepted by the cryptographic community since 2011 (ASIACRYPT 2011). Our aim is to open up the direction for implementing the useful leakage-resilient cryptographic schemes for future usage. ",
    "year": "2017",
    "Authors": [
      "Alawatugoda, J.",
      "Ragel, R.",
      "Eranga, D.",
      "Jayanath, N.",
      "Somathilaka, C."
    ],
    "venue": {
      "journal": "2016 IEEE International Conference on Information and Automation for Sustainability: Interoperable Sustainable Smart Systems for Next Generation, ICIAfS 2016"
    },
    "DOI": "10.1109/ICIAFS.2016.7946548",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85022036743&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "cryptography",
      "leakage resilience",
      "side-channels",
      "storage schemes"
    ]
  },
  {
    "type": "article",
    "title": "Machine Learning based Trust Computational Model for IoT Services",
    "abstract": "The Internet of Things has facilitated access to a large volume of sensitive information on each participating object in an ecosystem. This imposes many threats ranging from the risks of data management to the potential discrimination enabled by data analytics over delicate information such as locations, interests, and activities. To address these issues, the concept of trust is introduced as an important role in supporting both humans and services to overcome the perception of uncertainty and risks before making any decisions. However, establishing trust in a cyber world is a challenging task due to the volume of diversified influential factors from cyber-physical-systems. Hence, it is essential to have an intelligent trust computation model that is capable of generating accurate and intuitive trust values for prospective actors. Therefore, in this paper, a quantifiable trust assessment model is proposed. Built on this model, individual trust attributes are then calculated numerically. Moreover, a novel algorithm based on machine learning principles is devised to classify the extracted trust features and combine them to produce a final trust value to be used for decision making. Finally, our model's effectiveness is verified through a simulation. The results show that our method has advantages over other aggregation methods.",
    "year": "2018",
    "Authors": [
      "Jayasinghe, U.",
      "Lee, G. M.",
      "Um, T. W.",
      "Shi, Q."
    ],
    "venue": {
      "journal": "IEEE Transactions on Sustainable Computing",
      "volume": ""
    },
    "DOI": "10.1109/TSUSC.2018.2839623",
    "publication url": "https://ieeexplore.ieee.org/document/8364607/",
    "pdf": "",
    "presentation": "",
    "code": "",
    "tags": [
      "Clustering",
      "computational trust",
      "Machine Learning",
      "IoT"
    ]
  },
  {
    "type": "article",
    "title": "Modelling after-the-fact leakage for key exchange",
    "abstract": "Security models for two-party authenticated key exchange (AKE) protocols have developed over time to prove the security of AKE protocols even when the adversary learns certain secret values. In this work, we address more granular leakage: partial leakage of long-term secrets of protocol principals, even after the session key is established. We introduce a generic key exchange security model, which can be instantiated allowing bounded or continuous leakage, even when the adversary learns certain ephemeral secrets or session keys. Our model is the strongest known partial-leakage-based security model for key exchange protocols. We propose a generic construction of a two-pass leakage-resilient key exchange protocol that is secure in the proposed model, by introducing a new concept: the leakage-resilient NAXOS trick. We identify a special property for public-key cryptosystems: pair generation indistinguishability, and show how to obtain the leakage-resilient NAXOS trick from a pair generation indistinguishable leakage-resilient public-key cryptosystem.",
    "year": "2014",
    "Authors": [
      "Alawatugoda, J.",
      "Stebila, D.",
      "Boyd, C."
    ],
    "venue": {
      "journal": "ASIA CCS 2014 - Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security"
    },
    "DOI": "10.1145/2590296.2590317",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84939487969&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "After-the-fact",
      "Key exchange protocols",
      "Leakage-resilient",
      "NAXOS",
      "Security models",
      "Side-channel attacks"
    ]
  },
  {
    "type": "article",
    "title": "F5N : Nanopore Sequence Analysis Toolkit for Android Smartphones",
    "abstract": "F5N is the first ever Android application for nanopore sequence analysis on a mobile phone, comprised of popular tools for read alignment (Minimap2), sequence data manipulation (Samtools) and methylation calling (F5C/Nanopolish). On NA12878 nanopore data, F5N can perform a complete methylation calling pipeline on a mobile phone in \u223c15 minutes for a batch of 4000 nanopore reads (\u223c34 megabases). F5N is not only a toolkit but also a framework for integrating existing C/C++ based command line tools to run on Android. F5N will enable performing nanopore sequence analysis on-site when used with an ultra-portable nanopore sequencer (eg: MinION or the anticipated smidgION), consequently reducing the cost for special computers and high-speed Internet.",
    "year": "2020",
    "Authors": [
      "Samarakoon, Hiruna",
      "Punchihewa, Sanoj",
      "Senanayake, Anjana",
      "Ragel, Roshan",
      "Gamaarachchi, Hasindu"
    ],
    "DOI": "10.1038/s42003-020-01270-z",
    "pdf": "https://www.biorxiv.org/content/10.1101/2020.03.22.002030v2.full.pdf",
    "publication url": "https://doi.org/10.1101%2F2020.03.22.002030",
    "presentation": "",
    "code": "https://github.com/SanojPunchihewa/f5n",
    "tags": "nanopore sequence analysis"
  },
  {
    "type": "article",
    "title": "On the leakage-resilient key exchange",
    "abstract": "Typically, secure channels are constructed from an authenticated key exchange (AKE) protocol, which authenticates the communicating parties based on long-term public keys and establishes secret session keys. In this paper we address the partial leakage of long-term secret keys of key exchange protocol participants due to various side-channel attacks. Security models for two-party authenticated key exchange protocols have been developed over time to provide security even when the adversary learns certain secret values. This paper combines and extends the advances of security modelling for AKE protocols addressing more granular partial leakage of long-term secrets of protocol participants. Further, we fix some flaws in security proofs of previous leakage-resilient key exchange protocols.",
    "year": "2017",
    "Authors": [
      "Alawatugoda, J."
    ],
    "venue": {
      "journal": "Journal of Mathematical Cryptology",
      "volume": "11"
    },
    "DOI": "10.1515/jmc-2016-0003",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85037609844&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Key exchange protocols",
      "leakage-resilient cryptography",
      "security models"
    ]
  },
  {
    "type": "article",
    "title": "Protecting encrypted cookies from compression Side-Channel attacks",
    "abstract": "Compression is desirable for network applications as it saves bandwidth; however, when data is compressed before being encrypted, the amount of compression leaks information about the amount of redundancy in the plaintext. This side channel has led to successful CRIME and BREACH attacks on web traffic protected by the Transport Layer Security (TLS) protocol. The general guidance in light of these attacks has been to disable compression, preserving confidentiality but sacrificing bandwidth. In this paper, we examine two techniques\u2014heuristic separation of secrets and fixed-dictionary compression\u2014for enabling compression while protecting high-value secrets, such as cookies, from attack. We model the security offered by these techniques and report on the amount of compressibility that they can achieve.",
    "year": "2015",
    "Authors": [
      "Alawatugoda, J.",
      "Stebila, D.",
      "Boyd, C."
    ],
    "venue": {
      "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
      "volume": "8975"
    },
    "DOI": "10.1007/978-3-662-47854-7_6",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84949979249&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Side channel attack",
      "Cryptography",
      "Data compression"
    ]
  },
  {
    "type": "article",
    "title": "Public-Key Encryption In The Standard Model Against Strong Leakage Adversary",
    "abstract": "Over the years, security against adaptively chosen-ciphertext attacks (CCA2) is considered as the strongest security definition for public-key encryption schemes. With the uprise of side-channel attacks, new security definitions are proposed, addressing leakage of secret keys together with the standard CCA2 definition. Among the new security definitions, security against continuous and after-the-fact leakage-resilient CCA2 can be considered as the strongest security definition, which is called as security against (continuous) adaptively chosen-ciphertext leakage attacks (continuous CCLA2). In this paper, we present a construction of a public-key encryption scheme, namely LR-PKE, which satisfies the aforementioned security definition. The security of our public-key encryption scheme is proven in the standard model, under decision BDH assumption. Thus, we emphasize that our public-key encryption scheme LR-PKE is (continuous) CCLA2-secure in the standard model. For our construction of LR-PKE, we have used a strong one-time signature scheme and a leakage-resilient refreshing protocol as underlying building blocks. The leakage bound is 0.15nlogp\u22121 bits per leakage query, for a security parameter k and a statistical security parameter n\u2060, such that logp\u2265k and n is a function of k\u2060. It is possible to see that LR-PKE is efficient enough to be used for real-world usage.",
    "year": "2020",
    "Authors": [
      "Alawatugoda, Janaka"
    ],
    "venue": {
      "journal": "The Computer Journal",
      "volume": "63"
    },
    "DOI": "10.1093/comjnl/bxaa055",
    "pdf": "",
    "publication url": "http://dx.doi.org/10.1093/comjnl/bxaa055",
    "presentation": "",
    "code": "",
    "tags": "Public-Key Encryption"
  },
  {
    "type": "article",
    "title": "Review on leakage resilient key exchange security models",
    "abstract": "In leakage resilient cryptography, leakage resilient key exchange protocols are constructed to defend against leakage attacks. Then, the key exchange protocol is proved with leakage resilient security model to determine whether its security proof can provide the security properties it claimed or to find out any unexamined flaw during protocol building. It is an interesting work to review the meaningful security properties provided by these security models. This work review how a leakage resilient security model for a key exchange protocol has been evolved over years according to the increasing security requirement which covers a different range of attacks. The relationship on how an adversary capability in the leakage resilient security model can be related to real-world attack scenarios is studied. The analysis work for each leakage resilient security model here enables a better knowledge on how an adversary query addresses different leakage attacks setting, thereby understand the motive of design for a cryptographic primitive in the security model. \u00a9 2019 Kohat University of Science and Technology.",
    "year": "2019",
    "Authors": [
      "Wei, C.C.Z.",
      "Wen, C.C.",
      "Alawatugoda, J."
    ],
    "venue": {
      "journal": "International Journal of Communication Networks and Information Security",
      "volume": "11"
    },
    "DOI": "",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-85065514385&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Key exchange protocol",
      "Leakage attacks",
      "Leakage resilience",
      "Leakage-resilient cryptography",
      "Security models",
      "Side-channel attacks"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Security Vulnerabilities of the Cisco {IOS} Implementation of the {MPLS} Transport Profile",
    "book title": "Proceedings of the 2nd Workshop on Smart Energy Grid Security - {SEGS} {\\textquotesingle}14",
    "abstract": "We are interested in the security of the MPLS Transport Profile (MPLS-TP), in the context of smart-grid communication networks. The security guidelines of the MPLS-TP standards are written in a complex and indirect way, which led us to pose as hypothesis that vendor solutions might not implement them satisfactorily. To test this hypothesis, we investigated the Cisco implementation of two MPLS-TP OAM (Operations, Administration, and Maintenance) protocols: bidirectional forwarding detection (BFD), used to detect failures in label-switched paths (LSPs) and protection state coordination (PSC), used to coordinate protection switching. Critical smart grid applications, such as protection and control, rely on the protection switching feature controlled by BFD and PSC. We did find security issues with this implementation. We implemented a testbed with eight nodes that run the MPLS-TP enabled Cisco IOS; we demonstrated that an attacker who has access to only one cable (for two attacks) or two cables (for one attack) is able to harm the network at several points (e.g., disabling both working and protection LSPs). This occurred in spite of us implementing the security guidelines that are available from Cisco for IOS and MPLS-TP. The attacks use forged BFD or PSC messages, which induce a label-edge router (LER) into believing false information about an LSP. In one attack, the LER disables the operational LSP; in another attack, the LER continues to believe that a physically destroyed LSP is up and running; in yet another attack, both operational and backup LSPs are brought down. Our findings suggest that the MPLS-TP standard should be more explicit when it comes to security. For example, to thwart the attacks revealed here, it should mandate either hop by hop authentication (such as MACSec) at every node, or an ad-hoc authentication mechanism for BFD and PSC.",
    "year": "2014",
    "Authors": [
      "Jayasinghe, Upul",
      "Barreto, Sergio",
      "Popovic, Miroslav",
      "Tesfay, Teklemariam T.",
      "Boudec, Jean-Yves Le"
    ],
    "DOI": "10.1145/2667190.2667197",
    "pdf": "",
    "publication url": "https://doi.org/10.1145%2F2667190.2667197",
    "presentation": "",
    "code": "",
    "tags": [
      "Security Vulnerabilities",
      "Cisco",
      "IOS Implementation"
    ]
  },
  {
    "type": "article",
    "title": "Software implementation level countermeasures against the cache timing attack on advanced encryption standard",
    "abstract": "Advanced Encryption Standard (AES) is a symmetric key encryption algorithm which is extensively used in secure electronic data transmission. When introduced, although it was tested and declared as secure, in 2005, a researcher named Bernstein claimed that it is vulnerable to side channel attacks. The cache-based timing attack is the type of side channel attack demonstrated by Bernstein, which uses the timing variation in cache hits and misses. This kind of attacks can be prevented by masking the actual timing information from the attacker. Such masking can be performed by altering the original AES software implementation while preserving its semantics. This paper presents possible software implementation level countermeasures against Bernstein's cache timing attack. Two simple software based countermeasures based on the concept of \u201cconstant-encryption-time\u201d were demonstrated against the remote cache timing attack with positive outcomes, in which we establish a secured environment for the AES encryption.",
    "year": "2013",
    "Authors": [
      "Herath, U.",
      "Alawatugoda, J.",
      "Ragel, R."
    ],
    "venue": {
      "journal": "2013 IEEE 8th International Conference on Industrial and Information Systems, ICIIS 2013 - Conference Proceedings"
    },
    "DOI": "10.1109/ICIInfS.2013.6731958",
    "pdf": "",
    "publication url": "http://www.scopus.com/inward/record.url?eid=2-s2.0-84894501013&partnerID=MN8TOARS",
    "presentation": "",
    "code": "",
    "tags": [
      "Advanced Encryption Standard",
      "Cache Timing Attack",
      "Constant time encryption",
      "Side Channel Attack"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Trust-Based Data Controller for Personal Information Management",
    "book title": "2018 International Conference on Innovations in Information Technology (IIT)",
    "abstract": "In today's data-driven digital economy, user-related information works as oil to fuel the state of art applications and services. Consumers, who use these services, provide personal information to service providers, intentionally or unintentionally and often without considering their trustworthiness. However, this personal information often reveals one's identity and may lead users to face unexpected outcomes, ranging from uninvited advertisements to identity theft. To regulate such issues, the new General Data Protection Regulation (GDPR) act was introduced by the European Union in May 2018. As defined by the act, the data controller plays an important role in determining the purposes, conditions and the means of processing data without compromising the user identities for malicious intentions. Therefore, in this paper, we propose a trust-based data controller in which an intermediate authority named trust manager recommends preferable actions towards the data controller on preserving the privacy of the users in accordance with the GDPR act.",
    "year": "2018",
    "Authors": [
      "Jayasinghe, U.",
      "Lee, G. M.",
      "MacDermott, A."
    ],
    "DOI": "10.1109/INNOVATIONS.2018.8605979",
    "pdf": "",
    "presentation": "",
    "publication url": "https://ieeexplore.ieee.org/document/8605979",
    "code": "",
    "tags": [
      "GDPR",
      "PII",
      "Data Controllers",
      "Data Processors",
      "Privacy",
      "Trust management"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Data Mining System for Predicting a Winning Cricket Team",
    "book title": "16th International Conference on Industrial and Information Systems, {ICIIS} 2021, Kandy, Sri Lanka, September 12 - Nov. 12, 2021",
    "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u2019 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
    "year": "2021",
    "Authors": [
      "Hasanika, Dinithi",
      "Dilhara, Roshani",
      "Liyanage, Dulanjali",
      "Bandaranayake, Asitha",
      "Deegalla, Sampath"
    ],
    "DOI": "10.1109/ICIIS53135.2021.9660702",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
    "presentation": "",
    "code": "",
    "tags": [
      "Uncertainty",
      "Statistical analysis",
      "Games",
      "Machine learning",
      "Data mining",
      "artificial intelligence"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
    "book title": "2017 {IEEE} International Conference on Industrial and Information Systems, {ICIIS} 2017, Peradeniya, Sri Lanka, December 15-16, 2017",
    "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
    "year": "2017",
    "Authors": [
      "Somaskandhan, Pranavan",
      "Wijesinghe, Gihan",
      "Wijegunawardana, Leshan Bashitha",
      "Bandaranayake, Asitha",
      "Deegalla, Sampath"
    ],
    "DOI": "10.1109/ICIINFS.2017.8300399",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ICIINFS.2017.8300399",
    "presentation": "",
    "code": "",
    "tags": [
      "data mining",
      "artificial intelligence",
      "pattern classification",
      "sport",
      "statistical analysis",
      "support vector machines"
    ]
  },
  {
    "type": "article",
    "title": "Comparison of Optimization- and Rule-Based {EMS} for Domestic PV-Battery Installation with Time-Varying Local SoC Limits",
    "abstract": "Renewable energy is identified as a solution for the growing future electricity demand. Photovoltaic (PV) is a leading type of renewable energy source used for electricity generation. Among the PV systems, distributed PV systems are becoming popular among the domestic consumers and hence the number of domestic PV installations is on the rise continuously. Intermittent output power variations and inability to use the PV power during the night peak hours are major issues with PV systems. Energy storage is a possible mitigation technique for these issues. In order to effectively utilize local generations, storage, and loads, energy management system (EMS) becomes an essential component in future domestic PV installations. EMS for domestic consumers needs to be inexpensive, while a reasonable accuracy level is maintained. In this paper, optimization problem-based EMS and rule-based EMS were developed and compared to investigate the accuracy and the processing speed, thereby to select a fast and a curate EMS for a domestic PV installation. Furthermore, in the proposed EMS, a day-ahead generation and load profiles are generated from predictions, and thus the battery\u2019s state of charge (SoC) levels over a day is estimated through the EMS. In order to utilize the storage effectively, time-varying local maximum and minimum SoC limits for the battery are introduced, which are inside the global maximum and minimum SoC limits. With the aid of real-PV profiles and typical loading profiles, the EMS was implemented using optimization- and rule-based techniques with local SoC limits. The results verified that the rule-based EMS produced accurate results in comparison to optimization-based EMS with lesser processing time. Further results verified that the introduction of local SoC limits improved the performance of the EMS in the unforeseen conditions.",
    "year": "2019",
    "Authors": [
      "Herath, Akila",
      "Kodituwakku, Supun",
      "Dasanayake, Dinithi",
      "Binduhewa, Prabath J.",
      "Ekanayake, Janaka",
      "Samarakoon, Kamalanath"
    ],
    "venue": {
      "journal": "J. Electr. Comput. Eng.",
      "volume": "2019"
    },
    "DOI": "10.1155/2019/8162475",
    "pdf": "https://downloads.hindawi.com/journals/jece/2019/8162475.pdf",
    "publication url": "https://doi.org/10.1155/2019/8162475",
    "presentation": "",
    "code": "",
    "tags": ""
  },
  {
    "type": "article",
    "title": "Reporting Available Demand Response",
    "abstract": "Demand response is increasingly important in many power systems but Transmission System Operators (TSO) require confirmation that the response is available if it is to be used effectively. Demand response may be used to minimise the amount of spinning reserve obtained from partially loaded generators. The ability of the proposed smart metering communication system in the U.K. to report the available demand response from domestic appliances was examined. This communication system expects to send all data traffic at an average rate of about 190 Mbytes per minute through a central Data Communication Company (DCC) to any actor operating in the power system. It is unlikely that this communication system will, in addition, support reporting demand response in near real-time. Using load profiles of fridges, cooking appliances and washers and dryers, the load profiles of 40 000 houses were constructed. These load profiles were used to calculate the average number of load changes in a typical house, a 11/0.4 kV transformer and a high voltage substation. Using these average numbers of load changes and the number of transformers and substations in the U.K. power system, the number of messages sent by all smart meters in the U.K. was calculated. It is shown that the wide area network proposed for the U.K. need to send an additional 162 Mbytes per minute to report demand response in near real-time. Then, a hierarchically arranged communication system that follows the hierarchy of electrical network was examined. It was assumed that aggregating units are installed at distribution transformers and substations. It is shown that by aggregating and sending only measurement changes, the number of bytes sent through the U.K. smart metering communication system per minute could be reduced from 162 M to 30 k. This has important implications as the U.K. is now finalizing the specifications for smart metering communications for about 27 million smart electricity meters that will be installed in the period 2014-2020.",
    "year": "2013",
    "Authors": [
      "Samarakoon, Kamalanath",
      "Ekanayake, Janaka",
      "Jenkins, Nick"
    ],
    "venue": {
      "journal": "{IEEE} Trans. Smart Grid",
      "volume": "4"
    },
    "DOI": "10.1109/TSG.2013.2258045",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/TSG.2013.2258045",
    "presentation": "",
    "code": "",
    "tags": [
      "demand side management",
      "distribution networks",
      "power engineering computing",
      "refrigerators",
      "smart meters",
      "substations",
      "transformers",
      "wide area networks,Load management",
      "Smart meters",
      "Wide area networks",
      "Home appliances",
      "Power measurement",
      "Substations",
      "Communication networks"
    ]
  },
  {
    "type": "article",
    "title": "Investigation of Domestic Load Control to Provide Primary Frequency Response Using Smart Meters",
    "abstract": "The ability of smart meters to control domestic demand during system emergencies was investigated. Direct load control through the smart meters is unlikely to be able to provide primary frequency response because of communication delays. An alternative load control scheme that used a local frequency measurement from the smart meters was investigated. An experimental rig was developed, using commercially available components, to test and demonstrate the load control scheme. The amount of load to be controlled to limit the frequency drop of the Great Britain system to a set of minimum allowable frequencies was found using a simulation program. Operating speeds and the limitations of the components of the load controller in providing primary response are discussed. It is shown that if smart meters are to play any role in primary response then the speed at which the system frequency is measured must be increased very considerably (from around 3 s to 200 ms). This has important implications as the U.K. is now finalizing the specification for more than 20 million smart electricity meters that will be installed by 2020.",
    "year": "2012",
    "Authors": [
      "Samarakoon, Kamalanath",
      "Ekanayake, Janaka",
      "Jenkins, Nick"
    ],
    "venue": {
      "journal": "{IEEE} Trans. Smart Grid",
      "volume": "3"
    },
    "DOI": "10.1109/TSG.2011.2173219",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/TSG.2011.2173219",
    "presentation": "",
    "code": "",
    "tags": [
      "Switches",
      "Frequency control",
      "Load flow control",
      "Frequency response",
      "Frequency conversion",
      "Time frequency analysis",
      "delays",
      "domestic appliances",
      "frequency response",
      "load regulation",
      "power meters",
      "supply and demand"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Verified Protection Model of the seL4 Microkernel",
    "book title": "Verified Software: Theories, Tools, Experiments, Second International Conference, {VSTTE} 2008, Toronto, Canada, October 6-9, 2008. Proceedings",
    "abstract": "This paper presents a machine-checked high-level security analysis of seL4\u2014an evolution of the L4 kernel series targeted to secure, embedded devices. We provide an abstract specification of the seL4 access control system together with a formal proof that shows how confined subsystems can be enforced. All proofs and specifications in this paper are developed in the interactive theorem prover Isabelle/HOL.",
    "year": "2008",
    "Authors": [
      "Elkaduwe, Dhammika",
      "Klein, Gerwin",
      "Elphinstone, Kevin"
    ],
    "DOI": "10.1007/978-3-540-87873-5_11",
    "pdf": "",
    "publication url": "https://doi.org/10.1007/978-3-540-87873-5\\_11",
    "presentation": "",
    "code": "",
    "tags": [
      "Transitive Closure",
      "Access Control Model",
      "Physical Memory",
      "Protection Model",
      "Current System State"
    ]
  },
  {
    "type": "article",
    "title": "To Use or Not to Use: CPUs' Cache Optimization Techniques on GPGPUs",
    "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU\u2019s best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
    "year": "2018",
    "Authors": [
      "Thambawita, Vajira",
      "Ragel, Roshan G.",
      "Elkaduwe, Dhammika"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1810.04063"
    },
    "DOI": "10.48550/arXiv.1810.04063",
    "pdf": "https://arxiv.org/pdf/1810.04063",
    "publication url": "http://arxiv.org/abs/1810.04063",
    "presentation": "",
    "code": "",
    "tags": [
      "GPGPU",
      "CPU",
      "Cache Optimization",
      "CUDA",
      "Fermi Architecture"
    ]
  },
  {
    "type": "article",
    "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for {DNA} sequence matching",
    "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose raphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel AhoCorasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
    "year": "2018",
    "Authors": [
      "Thambawita, Vajira",
      "Ragel, Roshan G.",
      "Elkaduwe, Dhammika"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1811.10498"
    },
    "DOI": "10.48550/arXiv.1811.10498",
    "pdf": "https://arxiv.org/pdf/1811.10498.pdf",
    "publication url": "http://arxiv.org/abs/1811.10498",
    "presentation": "",
    "code": "",
    "tags": [
      "Aho-Corasick",
      "GPGPU",
      "DNA sequence matching"
    ]
  },
  {
    "type": "article",
    "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
    "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein\u2019s cache timing attack.",
    "year": "2014",
    "Authors": [
      "Jayasinghe, Darshana",
      "Ragel, Roshan G.",
      "Elkaduwe, Dhammika"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1403.7293"
    },
    "DOI": "10.48550/arXiv.1403.7293",
    "pdf": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
    "publication url": "http://arxiv.org/abs/1403.7293",
    "presentation": "",
    "code": "",
    "tags": [
      "side channel",
      "cache timing attack",
      "constant time encryption "
    ]
  },
  {
    "type": "article",
    "title": "To Use or Not to Use: Graphics Processing Units for Pattern Matching Algorithms",
    "abstract": "String matching is an important part in today\u2019s computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark. We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms. ",
    "year": "2014",
    "Authors": [
      "Thambawita, Vajira",
      "Ragel, Roshan G.",
      "Elkaduwe, Dhammika"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1412.7789"
    },
    "DOI": "10.48550/arXiv.1412.7789",
    "pdf": "https://arxiv.org/ftp/arxiv/papers/1412/1412.7789.pdf",
    "publication url": "http://arxiv.org/abs/1412.7789",
    "presentation": "",
    "code": "",
    "tags": [
      "GPU",
      "CUDA",
      "CPU",
      "Aho-Corasick algorithm",
      "String matching"
    ]
  },
  {
    "type": "article",
    "title": "To Use or Not to Use: Graphics Processing Units for Pattern Matching Algorithms",
    "abstract": " String matching is an important part in today\u2019s computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark. We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance han GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms. ",
    "year": "2014",
    "Authors": [
      "Thambawita, Vajira",
      "Ragel, Roshan G.",
      "Elkaduwe, Dhammika"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1412.7789"
    },
    "DOI": "10.48550/arXiv.1412.7789",
    "pdf": "https://arxiv.org/ftp/arxiv/papers/1412/1412.7789.pdf",
    "publication url": "http://arxiv.org/abs/1412.7789",
    "presentation": "",
    "code": "",
    "tags": [
      "GPU",
      "CUDA",
      "CPU",
      "Aho-Corasick algorithm",
      "String matching"
    ]
  },
  {
    "type": "article",
    "title": "seL4: formal verification of an operating-system kernel",
    "abstract": "We report on the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, hardware, and boot code. seL4 is a third-generation microkernel of L4 provenance, comprising 8700 lines of C and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels. We prove that the implementation always strictly follows our high-level abstract specification of kernel behavior. This encompasses traditional design and implementation safety properties such as that the kernel will never crash, and it will never perform an unsafe operation. It also implies much more: we can predict precisely how the kernel will behave in every possible situation.",
    "year": "2010",
    "Authors": [
      "Klein, Gerwin",
      "Andronick, June",
      "Elphinstone, Kevin",
      "Heiser, Gernot",
      "Cock, David",
      "Derrin, Philip",
      "Elkaduwe, Dhammika",
      "Engelhardt, Kai",
      "Kolanski, Rafal",
      "Norrish, Michael",
      "Sewell, Thomas",
      "Tuch, Harvey",
      "Winwood, Simon"
    ],
    "venue": {
      "journal": "Commun. {ACM}",
      "volume": "53"
    },
    "DOI": "10.1145/1743546.1743574",
    "pdf": "https://dl.acm.org/doi/pdf/10.1145/1743546.1743574",
    "publication url": "https://doi.org/10.1145/1743546.1743574",
    "presentation": "",
    "code": "",
    "tags": [
      "Software Engineering",
      "Reliability",
      "Software",
      "Cross-computing",
      "Theory of computation"
    ]
  },
  {
    "type": "inproceedings",
    "title": "seL4: formal verification of an {OS} kernel",
    "book title": "Proceedings of the 22nd {ACM} Symposium on Operating Systems Principles 2009, {SOSP} 2009, Big Sky, Montana, USA, October 11-14, 2009",
    "abstract": "Complete formal verification is the only known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels. ",
    "year": "2009",
    "Authors": [
      "Klein, Gerwin",
      "Elphinstone, Kevin",
      "Heiser, Gernot",
      "Andronick, June",
      "Cock, David",
      "Derrin, Philip",
      "Elkaduwe, Dhammika",
      "Engelhardt, Kai",
      "Kolanski, Rafal",
      "Norrish, Michael",
      "Sewell, Thomas",
      "Tuch, Harvey",
      "Winwood, Simon"
    ],
    "DOI": "10.1145/1629575.1629596",
    "pdf": "https://dl.acm.org/doi/pdf/10.1145/1629575.1629596",
    "publication url": "https://doi.org/10.1145/1629575.1629596",
    "presentation": "",
    "code": "",
    "tags": [
      "Isabelle/HOL",
      "L4",
      "microkernel",
      "seL4",
      "Operating Systems",
      "Software Engineering"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Kernel design for isolation and assurance of physical memory",
    "book title": "Proceedings of the 1st Workshop on Isolation and Integration in Embedded Systems, {IIES} '08, Glasgow, Scotland, April 1, 2008",
    "abstract": "Embedded systems are evolving into increasingly complex software systems. One approach to managing this software complexity is to divide the system into smaller, tractable components and provide strong isolation guarantees between them. This paper focuses on one aspect of the system\u2019s behaviour that is critical to any such guarantee: management of physical memory resources. We present the design of a kernel that has formally demonstrated the ability to make strong isolation guarantees of physical memory. We also present the macro-level performance characteristics of a kernel implementing the proposed design.",
    "year": "2008",
    "Authors": [
      "Elkaduwe, Dhammika",
      "Derrin, Philip",
      "Elphinstone, Kevin"
    ],
    "DOI": "10.1145/1435458.1435465",
    "pdf": "https://dl.acm.org/doi/pdf/10.1145/1435458.1435465",
    "publication url": "https://doi.org/10.1145/1435458.1435465",
    "presentation": "",
    "code": "",
    "tags": [
      "isolation",
      "seL4",
      "memory management",
      "embedded systems",
      "microkernels"
    ]
  },
  {
    "type": "article",
    "title": "An Ensemble Learning Approach for Electrocardiogram Sensor Based Human Emotion Recognition",
    "abstract": "Recently, researchers in the area of biosensor based human emotion recognition have used different types of machine learning models for recognizing human emotions. However, most of them still lack the ability to recognize human emotions with higher classification accuracy incorporating a limited number of bio-sensors. In the domain of machine learning, ensemble learning methods have been successfully applied to solve different types of real-world machine learning problems which require improved classification accuracies. Emphasising on that, this research suggests an ensemble learning approach for developing a machine learning model that can recognize four major human emotions namely: anger; sadness; joy; and pleasure incorporating electrocardiogram (ECG) signals. As feature extraction methods, this analysis combines four ECG signal based techniques, namely: heart rate variability; empirical mode decomposition; with-in beat analysis; and frequency spectrum analysis. The first three feature extraction methods are well-known ECG based feature extraction techniques mentioned in the literature, and the fourth technique is a novel method proposed in this study. The machine learning procedure of this investigation evaluates the performance of a set of well-known ensemble learners for emotion classification and further improves the classification results using feature selection as a prior step to ensemble model training. Compared to the best performing single biosensor based model in the literature, the developed ensemble learner has the accuracy gain of 10.77%. Furthermore, the developed model outperforms most of the multiple biosensor based emotion recognition models with a significantly higher classification accuracy gain.",
    "year": "2019",
    "Authors": [
      "Dissanayake, Theekshana",
      "Rajapaksha, Yasitha",
      "Ragel, Roshan G.",
      "Nawinne, Isuru"
    ],
    "venue": {
      "journal": "Sensors",
      "volume": "19"
    },
    "DOI": "10.3390/s19204495",
    "pdf": "https://www.mdpi.com/1424-8220/19/20/4495/pdf?version=1571300841",
    "publication url": "https://doi.org/10.3390/s19204495",
    "presentation": "",
    "code": "",
    "tags": [
      "bio-signal processing",
      "wearable computing",
      "ensemble learning",
      "electrocardiogram",
      "machine learning"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Non-contact Infant Sleep Apnea Detection",
    "book title": "14th Conference on Industrial and Information Systems, {ICIIS} 2019, Kandy, Sri Lanka, December 18-20, 2019",
    "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for detecting sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
    "year": "2019",
    "Authors": [
      "Jayatilaka, Gihan",
      "Weligampola, Harshana",
      "Sritharan, Suren",
      "Pathmanathan, Pankayraj",
      "Ragel, Roshan G.",
      "Nawinne, Isuru"
    ],
    "DOI": "10.1109/ICIIS47346.2019.9063269",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
    "presentation": "",
    "code": "",
    "tags": [
      "Sleep apnea",
      "Blood",
      "Neural networks",
      "Conferences",
      "Information systems",
      "Image edge detection",
      "biomedical optical imaging",
      "medical disorders",
      "medical image processing",
      "paediatrics",
      "patient monitoring",
      "pneumodynamics",
      "sleep",
      "video signal processing"
    ]
  },
  {
    "type": "article",
    "title": "Non-contact Infant Sleep Apnea Detection",
    "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
    "year": "2019",
    "Authors": [
      "Jayatilaka, Gihan",
      "Weligampola, Harshana",
      "Sritharan, Suren",
      "Pathmanathan, Pankayraj",
      "Ragel, Roshan G.",
      "Nawinne, Isuru"
    ],
    "venue": {
      "journal": "CoRR",
      "volume": "abs/1910.04725"
    },
    "DOI": "10.48550/arXiv.1910.04725",
    "pdf": "https://arxiv.org/pdf/1910.04725.pdf",
    "publication url": "http://arxiv.org/abs/1910.04725",
    "presentation": "",
    "code": "",
    "tags": [
      "sleep apnea",
      "video processing",
      "bio medical engineering",
      "pattern recognition"
    ]
  },
  {
    "type": "article",
    "title": "Switchable cache: utilising dark silicon for application specific cache optimisations",
    "abstract": "Caches are used to improve memory access time and energy consumption. The cache configuration which enables the best performance often differs between applications due to diverse memory access patterns. The authors present a new concept, called switchable cache, where multiple cache configurations exist on chip, leveraging the abundant transistors available due to what is known as the dark silicon phenomenon. Only one cache configuration is active at any given time based on the application under execution, while all other configurations remain inactive (dark). They describe an architecture to enable seamless integration of multiple cache configurations, and a novel design space exploration methodology to rapidly pre-determine the optimal set of configurations at design-time, for a given group of applications. For design spaces containing trillions of design points, the authors\u2019 exploration methodology always found the optimal solution in less than 2 s. The switchable cache improved memory access time by up to 26.2% when compared to a fixed cache.",
    "year": "2016",
    "Authors": [
      "Nawinne, Isuru",
      "Javaid, Haris",
      "Ragel, Roshan G.",
      "Parameswaran, Sri"
    ],
    "venue": {
      "journal": "{IET} Comput. Digit. Tech.",
      "volume": "10"
    },
    "DOI": "10.1049/iet-cdt.2015.0114",
    "pdf": "https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/iet-cdt.2015.0114",
    "publication url": "https://doi.org/10.1049/iet-cdt.2015.0114",
    "presentation": "",
    "code": "",
    "tags": ""
  },
  {
    "type": "article",
    "title": "Exploring Multilevel Cache Hierarchies in Application Specific MPSoCs",
    "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00d7 higher in our method, which is still a mere 3.6 \u00d7 10 -5 % of the entire design space, and took 6.08 h.",
    "year": "2015",
    "Authors": [
      "Nawinne, Isuru",
      "Javaid, Haris",
      "Ragel, Roshan G.",
      "Radhakrishnan, Swarnalatha",
      "Parameswaran, Sri"
    ],
    "venue": {
      "journal": "{IEEE} Trans. Comput. Aided Des. Integr. Circuits Syst.",
      "volume": "34"
    },
    "DOI": "10.1109/TCAD.2015.2445736",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/TCAD.2015.2445736",
    "presentation": "",
    "code": "",
    "tags": [
      "Algorithm design and analysis",
      "Hardware",
      "Program processors",
      "Space exploration",
      "Integrated circuit modeling",
      "Mathematical model",
      "Optimization,cache storage",
      "iterative methods",
      "system-on-chip"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Hardware-based fast exploration of cache hierarchies in application specific MPSoCs",
    "book title": "Design, Automation {\\&} Test in Europe Conference {\\&} Exhibition, {DATE} 2014, Dresden, Germany, March 24-28, 2014",
    "abstract": "Multi-level caches are widely used to improve the memory access speed of multiprocessor systems. Deciding on a suitable set of cache memories for an application specific embedded system's memory hierarchy is a tedious problem, particularly in the case of MPSoCs. To accurately determine the number of hits and misses for all the configurations in the design space of an MPSoC, researchers extract the trace first using Instruction set simulators and then simulate using a software simulator. Such simulations take several hours to months. We propose a novel method based on specialized hardware which can quickly simulate the design space of cache configurations for a shared memory multiprocessor system on an FPGA, by analyzing the memory traces and calculating the cache hits and misses simultaneously. We demonstrate that our simulator can explore the cache design space of a quad-core system with private L 1 caches and a shared L 2 cache, over a range of standard benchmarks, taking as less as 0.106 seconds per million memory accesses, which is up to 456 times faster than the fastest known software based simulator. Since we emulate the program and analyze memory traces simultaneously, we eliminate the need to extract multiple memory access traces prior to simulation, which saves a significant amount of time during the design stage.",
    "year": "2014",
    "Authors": [
      "Nawinne, Isuru",
      "Schneider, Josef",
      "Javaid, Haris",
      "Parameswaran, Sri"
    ],
    "DOI": "10.7873/DATE.2014.296",
    "pdf": "",
    "publication url": "https://doi.org/10.7873/DATE.2014.296",
    "presentation": "",
    "code": "",
    "tags": [
      "Space exploration",
      "Hardware",
      "Field programmable gate arrays",
      "Software",
      "Energy consumption",
      "Real-time systems",
      "Analytical models",
      "cache storage",
      "shared memory systems",
      "system-on-chip"
    ]
  },
  {
    "type": "inproceedings",
    "title": "Latency-constrained binding of data flow graphs to energy conscious GALS-based MPSoCs",
    "book title": "2013 {IEEE} International Symposium on Circuits and Systems (ISCAS2013), Beijing, China, May 19-23, 2013",
    "abstract": "Mapping tasks to cores in an Multiprocessor System-on-Chip (MPSoC) to meet constraints is widely investigated. Thus far the data flow graphs used for binding have been limited to acyclic graphs or have been single rate. In this paper we generalize the approach by allowing DFGs to be cyclic and multi rate. We further improve energy consumption by setting frequency per core in a Globally Asynchronous and Locally Synchronous (GALS) architecture (by the distribution of slack). A design flow is proposed with these two approaches to form a latency constrained and energy efficient binding. A generalized solution is proposed, compared to state-of-the-art, using improvements in formulation, data structures and heuristics. Eight benchmarks are experimented upon for mesh and pipeline architectures. Our heuristics achieve significant simulation speedup compared to the state-of-the-art and provide a solution which is 2.5% lower (26% worst case) than the optimal, but the solution is obtained 40x quicker (average case). Such a speedup allows us to rapidly explore a large design space.",
    "year": "2013",
    "Authors": [
      "Ambrose, Jude Angelo",
      "Nawinne, Isuru",
      "Parameswaran, Sri"
    ],
    "DOI": "10.1109/ISCAS.2013.6572070",
    "pdf": "",
    "publication url": "https://doi.org/10.1109/ISCAS.2013.6572070",
    "presentation": "",
    "code": "",
    "tags": [
      "Ports (Computers)",
      "Convex functions",
      "Program processors",
      "Data structures",
      "Mathematical model",
      "Flow graphs",
      "data flow graphs",
      "integrated circuit design",
      "multiprocessing systems",
      "system-on-chip"
    ]
  }
]